\section{Franks's Snippets}
Here goes Franks's text.

\subsection{Formulation as a sparse coding problem:}

In general the inpainting problem can be seen as a Maximum Likelihood Estimation (MLE) problem where the objective is to fill the missing pixels with most likely values, given the observed data. We represent the known values of the image through sparse enconding and during the process, infer pixel values at the locations of the unknown pixels, using the characteristics of the encoding basis. Popular bases include Discrete Cosine Transforms (DCT), Haar wavelets etc. which demonstrate favorable qualities for image encoding as they exhibit characteristics similar to generic image features. To achieve the sparse encoding we use the matching pursuit algorithm which serves to meet the following criterion
 		z* \ni \arg\max_{z} ||\mathbf{M}(\mathbf{x}-\mathbf{U}\mathbf{z}) ||_2
		s.t. ||z_0||  \leqslant K      (insert equation line 36 lecture 9).
Where \mathbf{M} is the masking matrix, \mathbf{x} is the observed pixels, \mathbf{U} is the dictionary matrix and \mathbf{z} are its sparse coefficients. 

Inpainting through sparse coding relies on infering unknown values based on the impact that the known pixels incur on the chosen basis. Therefore, for a given genre of images it is advantageous to utilize a custom dictionary which can easily encode the given genre's typical image characteristics. For example  in (Elad, Querre, Donoho), curvelets were demonstrated to be specifically efficient at encoding cartoon images. 

So far in the technique mentioned, the image is divided into individual patches on which the sparse encodings are found. This approach disregards the spatial distribution of the occlusions and is hence sensitive to images where certain patches contain little known information. In (Criminisi) a method is proposed which first ranks the divided patches with a confidence criterion that favors patches with more known pixel values. Then, dense information from the boundary patches of the masked regions are propagated throughout the occluded region. Inspired by this work, we pursue here, two ways of propagating valuable image information beyond the boundaries of one patch.

\subsection{Valuable Information Propagation (VIP)}
To tackle the issue of densely populated masks, one of our approaches was to infer information from the surrounding, better known neighbours. The patches are ranked by a confidence criterion, similar to the works of (Criminisi et al.) we employ here the proportion of known pixel values within a patch, as a quality measure. Propagating information from better to poorer patches is then done by performing inpainting on an imaginary patch which is the concatenation of the poor patch's boundaries and its corresponding better neighbour. Once this imaginary patch's pixels have been infered, parts of the poorer neighbour's boundary missing pixels are chosen at random, and updated. This step allows for the propagation of information from the better neighbouring patch, while also reserving some of the final reconstruction influence for the poorer patch itself. The proportion of the masked pixels updated during this step is controlled by a parameter \epsilon \in \left] 0,1 \right[, which controls the amount of information propagated from the neighbour. The boundary width i.e. the band of pixels that make up the boundary is also parameterized as a function of the patch size. This value determines the autonomy that a given poor pixel has over its final image reconstruction. The algorithm works as follows

   \usepackage{algorithmicx}
    \usepackage[ruled]{algorithm}
    \usepackage[noend]{algpseudocode}

\vspace{-0.2cm}%
\alglanguage{pseudocode}
\begin{algorithm}[h]
\small
\caption{Valuable Information Propagation}
\label{Algorithm:VIP}
\begin{algorithmic}[1]
\Create{$\mathbf{Descending patch quality order}$}{vector $Rank$}
  %%  \LineComment{\emph{Quick check if $x$ is in mCBF}}
    \For {$i = 1 \to length(Rank)$}
            %%\If {$mCBF.C_{f_i(x)\%N}$ == 0}
                %%\State \textbf{return}
            %%\EndIf
	SparseCoding of patch $i$
	update mask vector in  \mathbf{M} and image vector in  \mathbf{X} corresponding to patch i
	
	    \For {$j = 1 \to #Neighbours$}
		\If {$#Masked values_j}$ >= \mathbf{threshold}}
               	 \State {Perform information propagation from i to j}
			update mask and pixel values of j
	            \EndIf
	    \EndFor
    \EndFor
    
\Statex
\end{algorithmic}
  \vspace{-0.4cm}%
\end{algorithm}

\subsection {Discussion on Using a shorter dictionary}

As discussed in (lecture 9 slide 38, to be referenced), the recovery of a representation using matching pursuit is prone to the coherence amongst the dictionary's atoms. For a fixed dimensionality, the more atoms contained in the dictionary, the higher the chances of there being greater coherence, leading to poorer reconstructions. The brevity of our learned dictionary not only allows for the low error reconstructions compared to baseline techniques as depicted in fig(to put in comparison figure), but also, does so at a faster rate since the matching pursuit process searches through less atoms. Reconstruction speed is of great consideration especially when concerned with inpaiting on large data sets, videos etc.
